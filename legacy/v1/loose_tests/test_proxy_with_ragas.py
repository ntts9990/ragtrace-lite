#!/usr/bin/env python3
"""
í”„ë¡ì‹œë¥¼ í†µí•œ RAGAS ì§ì ‘ í…ŒìŠ¤íŠ¸
"""
import os
import sys
import json
from datasets import Dataset
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy


def test_ragas_with_proxy():
    """RAGASì™€ í”„ë¡ì‹œ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ§ª RAGAS-í”„ë¡ì‹œ í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # í™˜ê²½ ì„¤ì •
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    
    # í”„ë¡ì‹œê°€ ì ìš©ëœ LLM ìƒì„±
    print("\n1ï¸âƒ£ í”„ë¡ì‹œ LLM ìƒì„±")
    llm = create_llm(config)
    print(f"âœ… LLM íƒ€ì…: {type(llm).__name__}")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = {
        'question': ['í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?'],
        'answer': ['í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.'],
        'contexts': [['ì„œìš¸íŠ¹ë³„ì‹œëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ìµœëŒ€ ë„ì‹œì…ë‹ˆë‹¤.']],
        'ground_truths': [['í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.']]
    }
    
    dataset = Dataset.from_dict(test_data)
    print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±: {len(dataset)}ê°œ í•­ëª©")
    
    # ë©”íŠ¸ë¦­ ì„¤ì •
    print("\n2ï¸âƒ£ ë©”íŠ¸ë¦­ ì„¤ì •")
    faithfulness.llm = llm
    answer_relevancy.llm = llm
    
    metrics = [faithfulness, answer_relevancy]
    print(f"âœ… ë©”íŠ¸ë¦­ ì„¤ì • ì™„ë£Œ: {[m.name for m in metrics]}")
    
    # í‰ê°€ ì‹¤í–‰
    print("\n3ï¸âƒ£ RAGAS í‰ê°€ ì‹¤í–‰")
    print("-" * 50)
    
    try:
        result = evaluate(
            dataset=dataset,
            metrics=metrics,
            llm=llm,
            raise_exceptions=False,  # íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ
            show_progress=True
        )
        
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
        
        # ê²°ê³¼ í™•ì¸
        if hasattr(result, 'to_pandas'):
            df = result.to_pandas()
            print("\nğŸ“Š í‰ê°€ ê²°ê³¼:")
            print(df)
            
            # ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ í™•ì¸
            print("\nğŸ“ˆ ë©”íŠ¸ë¦­ë³„ ì ìˆ˜:")
            for col in df.columns:
                if col not in ['question', 'answer', 'contexts', 'ground_truths']:
                    print(f"  - {col}: {df[col].dtype}")
                    if df[col].dtype in ['float64', 'int64']:
                        print(f"    ê°’: {df[col].iloc[0]}")
                    else:
                        print(f"    ê°’ íƒ€ì…: {type(df[col].iloc[0])}")
                        print(f"    ê°’: {str(df[col].iloc[0])[:50]}...")
        
        # ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ í™•ì¸
        if hasattr(result, 'scores'):
            print("\nğŸ“Š ì ìˆ˜ ë”•ì…”ë„ˆë¦¬:")
            if isinstance(result.scores, dict):
                for key, value in result.scores.items():
                    print(f"  - {key}: {value}")
            else:
                print(f"scores íƒ€ì…: {type(result.scores)}")
                print(f"scores ë‚´ìš©: {result.scores}")
                
    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


def test_proxy_responses():
    """í”„ë¡ì‹œì˜ ì‹¤ì œ ì‘ë‹µ í™•ì¸"""
    print("\n\n4ï¸âƒ£ í”„ë¡ì‹œ ì‘ë‹µ ìƒì„¸ í™•ì¸")
    print("=" * 70)
    
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    llm = create_llm(config)
    
    # faithfulness í…ŒìŠ¤íŠ¸
    prompt = """Given the following information, extract factual statements:
Answer: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 950ë§Œ ëª…ì…ë‹ˆë‹¤.

Extract all factual claims from the answer."""
    
    print("ğŸ“Š Faithfulness í”„ë¡¬í”„íŠ¸:")
    print(prompt)
    print("\nì‘ë‹µ:")
    response = llm._call(prompt)
    print(response)
    
    # JSON íŒŒì‹± í™•ì¸
    try:
        data = json.loads(response)
        print(f"\nâœ… JSON íŒŒì‹± ì„±ê³µ: {list(data.keys())}")
    except:
        print("\nâŒ JSON íŒŒì‹± ì‹¤íŒ¨")


if __name__ == "__main__":
    test_ragas_with_proxy()
    test_proxy_responses()