#!/usr/bin/env python3
"""
RAGAS í”„ë¡¬í”„íŠ¸ ë¶„ì„
"""
import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragas.metrics import faithfulness, answer_relevancy
# from ragas.metrics._faithfulness import FaithfulnessStatements
from datasets import Dataset


def test_ragas_prompts():
    """RAGASê°€ ì‚¬ìš©í•˜ëŠ” ì‹¤ì œ í”„ë¡¬í”„íŠ¸ í™•ì¸"""
    print("ğŸ” RAGAS í”„ë¡¬í”„íŠ¸ ë¶„ì„")
    print("=" * 70)
    
    # 1. Faithfulness í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n1ï¸âƒ£ Faithfulness í”„ë¡¬í”„íŠ¸:")
    print("-" * 50)
    
    # statement_generator_prompt í™•ì¸
    if hasattr(faithfulness, 'statement_generator_prompt'):
        prompt = faithfulness.statement_generator_prompt
        print(f"í”„ë¡¬í”„íŠ¸ íƒ€ì…: {type(prompt)}")
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸
        if hasattr(prompt, 'instruction'):
            print(f"\nì§€ì‹œì‚¬í•­:")
            print(prompt.instruction)
        
        if hasattr(prompt, 'examples'):
            print(f"\nì˜ˆì‹œ ê°œìˆ˜: {len(prompt.examples) if prompt.examples else 0}")
        
        if hasattr(prompt, 'output_model'):
            print(f"\nì¶œë ¥ ëª¨ë¸: {prompt.output_model}")
            # Pydantic ëª¨ë¸ í•„ë“œ í™•ì¸
            if hasattr(prompt.output_model, '__fields__'):
                print("í•„ë“œë“¤:")
                for field_name, field_info in prompt.output_model.__fields__.items():
                    print(f"  - {field_name}: {field_info}")
    
    # 2. NLI í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n\n2ï¸âƒ£ NLI (Natural Language Inference) í”„ë¡¬í”„íŠ¸:")
    print("-" * 50)
    
    if hasattr(faithfulness, 'nli_prompt'):
        prompt = faithfulness.nli_prompt
        print(f"í”„ë¡¬í”„íŠ¸ íƒ€ì…: {type(prompt)}")
        
        if hasattr(prompt, 'instruction'):
            print(f"\nì§€ì‹œì‚¬í•­:")
            print(prompt.instruction)
        
        if hasattr(prompt, 'output_model'):
            print(f"\nì¶œë ¥ ëª¨ë¸: {prompt.output_model}")
    
    # 3. Answer Relevancy í”„ë¡¬í”„íŠ¸ í™•ì¸
    print("\n\n3ï¸âƒ£ Answer Relevancy í”„ë¡¬í”„íŠ¸:")
    print("-" * 50)
    
    if hasattr(answer_relevancy, 'question_generation_prompt'):
        prompt = answer_relevancy.question_generation_prompt
        print(f"í”„ë¡¬í”„íŠ¸ íƒ€ì…: {type(prompt)}")
        
        if hasattr(prompt, 'instruction'):
            print(f"\nì§€ì‹œì‚¬í•­:")
            print(prompt.instruction)
        
        if hasattr(prompt, 'output_model'):
            print(f"\nì¶œë ¥ ëª¨ë¸: {prompt.output_model}")
            if hasattr(prompt.output_model, '__fields__'):
                print("í•„ë“œë“¤:")
                for field_name, field_info in prompt.output_model.__fields__.items():
                    print(f"  - {field_name}: {field_info}")


def test_expected_output_format():
    """ì˜ˆìƒ ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ” ì˜ˆìƒ ì¶œë ¥ í˜•ì‹")
    print("=" * 70)
    
    # faithfulness ë©”íŠ¸ë¦­ì˜ ì†ì„± í™•ì¸
    print("\n1ï¸âƒ£ Faithfulness ë©”íŠ¸ë¦­ ì†ì„±:")
    print(f"ë©”íŠ¸ë¦­ ì´ë¦„: {faithfulness.name}")
    print(f"ì†ì„±ë“¤: {[attr for attr in dir(faithfulness) if not attr.startswith('_')]}")


if __name__ == "__main__":
    test_ragas_prompts()
    test_expected_output_format()