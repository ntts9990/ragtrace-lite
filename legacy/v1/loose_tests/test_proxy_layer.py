#!/usr/bin/env python3
"""
HCX-RAGAS í”„ë¡ì‹œ ë ˆì´ì–´ í…ŒìŠ¤íŠ¸
"""
import os
import json
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm
from ragtrace_lite.hcx_proxy import HCXRAGASProxy


# RAGASê°€ ì‹¤ì œë¡œ ë³´ë‚´ëŠ” í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
RAGAS_PROMPTS = {
    'faithfulness': """Given the following information, extract factual statements:
Question: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?
Answer: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì€ ì•½ 950ë§Œ ëª…ì˜ ì¸êµ¬ê°€ ê±°ì£¼í•˜ëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ì˜ ë„ì‹œì…ë‹ˆë‹¤.

Extract all factual claims from the answer.""",
    
    'answer_relevancy': """Generate a question for the given answer.
Answer: ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë©° ì•½ 950ë§Œ ëª…ì´ ê±°ì£¼í•©ë‹ˆë‹¤.

The question should be relevant to the answer.""",
    
    'context_precision': """Given the following context and question, determine if the context is relevant.
Context: ì„œìš¸íŠ¹ë³„ì‹œëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ìµœëŒ€ ë„ì‹œë¡œ, ì •ì¹˜, ê²½ì œ, ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤.
Question: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?

Is the context relevant? Respond with relevant: 1 or relevant: 0""",
    
    'context_recall': """Analyze if the statements are supported by the context.
Context: ë¼ë©´ì„ ë§Œë“¤ë ¤ë©´ ë¬¼ì„ ë“ì¸ í›„ ë©´ê³¼ ìŠ¤í”„ë¥¼ ë„£ê³  3-4ë¶„ê°„ ì¡°ë¦¬í•©ë‹ˆë‹¤.
Statements:
1. ë¼ë©´ ì¡°ë¦¬ì—ëŠ” ë¬¼ì´ í•„ìš”í•˜ë‹¤
2. ë©´ê³¼ ìŠ¤í”„ë¥¼ ë„£ì–´ì•¼ í•œë‹¤
3. ì¡°ë¦¬ ì‹œê°„ì€ 10ë¶„ì´ë‹¤

For each statement, indicate 1 if supported, 0 if not."""
}


def test_proxy_functionality():
    """í”„ë¡ì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ§ª HCX-RAGAS í”„ë¡ì‹œ ë ˆì´ì–´ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    # ì„¤ì • ë¡œë“œ
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    
    # LLM ìƒì„± (í”„ë¡ì‹œ í¬í•¨)
    print("\n1ï¸âƒ£ LLM ìƒì„± (í”„ë¡ì‹œ ì ìš©)")
    print("-" * 50)
    
    try:
        llm = create_llm(config)
        print(f"âœ… LLM íƒ€ì…: {type(llm).__name__}")
        print(f"âœ… í”„ë¡ì‹œ ì ìš© í™•ì¸: {'HCXRAGASProxy' in str(type(llm))}")
        
        if isinstance(llm, HCXRAGASProxy):
            print("âœ… HCXê°€ í”„ë¡ì‹œë¡œ ê°ì‹¸ì§")
        else:
            print("âŒ í”„ë¡ì‹œê°€ ì ìš©ë˜ì§€ ì•ŠìŒ")
            return
            
    except Exception as e:
        print(f"âŒ LLM ìƒì„± ì‹¤íŒ¨: {e}")
        return
    
    # ê° ë©”íŠ¸ë¦­ë³„ í…ŒìŠ¤íŠ¸
    print("\n2ï¸âƒ£ ë©”íŠ¸ë¦­ë³„ í”„ë¡ì‹œ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    for metric_name, prompt in RAGAS_PROMPTS.items():
        print(f"\nğŸ“Š {metric_name.upper()} í…ŒìŠ¤íŠ¸")
        print("=" * 40)
        
        try:
            # í”„ë¡ì‹œ í˜¸ì¶œ
            response = llm._call(prompt)
            print(f"ğŸ“¤ í”„ë¡ì‹œ ì‘ë‹µ:\n{response}")
            
            # JSON íŒŒì‹± í™•ì¸
            try:
                data = json.loads(response)
                print(f"\nâœ… JSON íŒŒì‹± ì„±ê³µ!")
                print(f"   êµ¬ì¡°: {json.dumps(data, ensure_ascii=False, indent=2)}")
                
                # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                if metric_name == 'faithfulness' and 'statements' in data:
                    print(f"   âœ… statements í•„ë“œ í™•ì¸: {len(data['statements'])}ê°œ")
                elif metric_name == 'answer_relevancy' and 'question' in data:
                    print(f"   âœ… question í•„ë“œ í™•ì¸: {data['question'][:50]}...")
                elif metric_name == 'context_precision' and 'relevant' in data:
                    print(f"   âœ… relevant í•„ë“œ í™•ì¸: {data['relevant']}")
                elif metric_name == 'context_recall' and 'attributed' in data:
                    print(f"   âœ… attributed í•„ë“œ í™•ì¸: {data['attributed']}")
                    
            except json.JSONDecodeError as e:
                print(f"\nâŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            print(f"\nâŒ í”„ë¡ì‹œ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "-" * 40)
    
    # ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    # ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡¬í”„íŠ¸
    unknown_prompt = "ì´ê²ƒì€ RAGAS ë©”íŠ¸ë¦­ì´ ì•„ë‹Œ ì¼ë°˜ ì§ˆë¬¸ì…ë‹ˆë‹¤."
    try:
        response = llm._call(unknown_prompt)
        print(f"ì¼ë°˜ í”„ë¡¬í”„íŠ¸ ì‘ë‹µ: {response[:100]}...")
        print("âœ… ì•Œ ìˆ˜ ì—†ëŠ” í”„ë¡¬í”„íŠ¸ë„ ì •ìƒ ì²˜ë¦¬")
    except Exception as e:
        print(f"âŒ ì¼ë°˜ í”„ë¡¬í”„íŠ¸ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 70)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def test_schema_validation():
    """ìŠ¤í‚¤ë§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    print("\n\n4ï¸âƒ£ ìŠ¤í‚¤ë§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("-" * 50)
    
    # ê°€ì§œ í”„ë¡ì‹œë¡œ ë‚´ë¶€ ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
    from ragtrace_lite.llm_factory import LLMAdapterWrapper, HcxAdapter
    
    # ë”ë¯¸ HCX ìƒì„±
    class DummyHCX:
        def _call(self, prompt, **kwargs):
            return "í…ŒìŠ¤íŠ¸ ì‘ë‹µ"
    
    proxy = HCXRAGASProxy(DummyHCX())
    
    # ê° ë©”íŠ¸ë¦­ë³„ ë³€í™˜ í…ŒìŠ¤íŠ¸
    test_cases = {
        'faithfulness': [
            "1. ì²« ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤. 2. ë‘ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤.",
            "- ë¼ë©´ì€ ë§›ìˆë‹¤\n- ê¹€ì¹˜ë„ ë§›ìˆë‹¤",
            "ë‹¨ì¼ ë¬¸ì¥ í…ŒìŠ¤íŠ¸"
        ],
        'answer_relevancy': [
            '"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"ë¼ëŠ” ì§ˆë¬¸',
            'ì§ˆë¬¸: ì„œìš¸ì˜ ì¸êµ¬ëŠ” ëª‡ ëª…ì¸ê°€ìš”?',
            'ì´ê²ƒì€ ì§ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤'
        ],
        'context_precision': [
            "ì˜ˆ, ë§¤ìš° ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤.",
            "ì•„ë‹ˆì˜¤, ì „í˜€ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤.",
            "ê´€ë ¨ì„±ì´ ì• ë§¤í•©ë‹ˆë‹¤."
        ]
    }
    
    for metric, test_inputs in test_cases.items():
        print(f"\n{metric} ë³€í™˜ í…ŒìŠ¤íŠ¸:")
        for inp in test_inputs:
            result = proxy._force_convert(inp, metric)
            print(f"  ì…ë ¥: {inp[:30]}...")
            print(f"  ì¶œë ¥: {json.dumps(result, ensure_ascii=False)}")


if __name__ == "__main__":
    # ë©”ì¸ í…ŒìŠ¤íŠ¸
    test_proxy_functionality()
    
    # ìŠ¤í‚¤ë§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸
    test_schema_validation()