#!/usr/bin/env python3
"""
Faithfulness ë¬¸ì œ ë””ë²„ê¹…
"""
import os
import sys
import json
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm
from langchain_core.prompt_values import StringPromptValue


def test_ragas_calls():
    """RAGASê°€ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” RAGAS í˜¸ì¶œ ë°©ì‹ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    llm = create_llm(config)
    
    # 1. _call í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ _call ë©”ì„œë“œ í…ŒìŠ¤íŠ¸:")
    prompt = """Given a question and an answer, analyze the complexity of each sentence in the answer. Break down each sentence into one or more fully understandable statements. Ensure that no pronouns are used in any statement. Format the outputs in JSON.

question: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?
answer: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.

output:"""
    
    response = llm._call(prompt)
    print(f"ì‘ë‹µ: {response}")
    print(f"íƒ€ì…: {type(response)}")
    
    # 2. generate í…ŒìŠ¤íŠ¸ (RAGASê°€ ì‚¬ìš©í•˜ëŠ” ë°©ì‹)
    print("\n\n2ï¸âƒ£ generate ë©”ì„œë“œ í…ŒìŠ¤íŠ¸:")
    prompt_value = StringPromptValue(text=prompt)
    result = llm.generate([prompt_value])
    print(f"ê²°ê³¼ íƒ€ì…: {type(result)}")
    print(f"generations: {result.generations}")
    if result.generations and result.generations[0]:
        text = result.generations[0][0].text
        print(f"í…ìŠ¤íŠ¸: {text}")
        print(f"í…ìŠ¤íŠ¸ íƒ€ì…: {type(text)}")
        
        # JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
        try:
            data = json.loads(text)
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {data}")
        except Exception as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    # 3. agenerate í…ŒìŠ¤íŠ¸
    print("\n\n3ï¸âƒ£ agenerate ë©”ì„œë“œ í…ŒìŠ¤íŠ¸:")
    import asyncio
    
    async def test_agenerate():
        result = await llm.agenerate([prompt_value])
        print(f"ë¹„ë™ê¸° ê²°ê³¼ íƒ€ì…: {type(result)}")
        if result.generations and result.generations[0]:
            text = result.generations[0][0].text
            print(f"í…ìŠ¤íŠ¸: {text}")
    
    asyncio.run(test_agenerate())
    
    # 4. NLI í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
    print("\n\n4ï¸âƒ£ NLI í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸:")
    nli_prompt = """Your task is to judge the faithfulness of a series of statements based on a given context. For each statement you must return a verdict.

Context: ì„œìš¸íŠ¹ë³„ì‹œëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ìµœëŒ€ ë„ì‹œì…ë‹ˆë‹¤.

statements:
sentence_1: í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.

output:"""
    
    response = llm._call(nli_prompt)
    print(f"NLI ì‘ë‹µ: {response}")


if __name__ == "__main__":
    test_ragas_calls()