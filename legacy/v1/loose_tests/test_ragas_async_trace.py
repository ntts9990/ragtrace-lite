#!/usr/bin/env python3
"""
RAGAS ë¹„ë™ê¸° í˜¸ì¶œ ì¶”ì 
"""
import asyncio
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm
from ragtrace_lite.hcx_proxy import HCXRAGASProxy
from langchain_core.outputs import LLMResult, Generation
from typing import List, Any, Union
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import faithfulness


class TracingProxy(HCXRAGASProxy):
    """í˜¸ì¶œ ì¶”ì ì„ ìœ„í•œ í”„ë¡ì‹œ"""
    
    async def agenerate(self, prompts: List[Union[str, Any]], **kwargs: Any):
        """ì¶”ì  ê¸°ëŠ¥ì´ ìˆëŠ” agenerate"""
        print(f"\nğŸ” agenerate í˜¸ì¶œë¨")
        print(f"  - prompts íƒ€ì…: {type(prompts)}")
        print(f"  - prompts ê°œìˆ˜: {len(prompts) if isinstance(prompts, list) else 1}")
        
        # ì›ë˜ ë©”ì„œë“œ í˜¸ì¶œ
        coro = super().agenerate(prompts, **kwargs)
        print(f"  - ë°˜í™˜ íƒ€ì…: {type(coro)}")
        print(f"  - ì½”ë£¨í‹´?: {asyncio.iscoroutine(coro)}")
        
        # ì‹¤í–‰í•˜ê³  ê²°ê³¼ í™•ì¸
        try:
            result = await coro
            print(f"  - await í›„ ê²°ê³¼ íƒ€ì…: {type(result)}")
            print(f"  - LLMResult?: {isinstance(result, LLMResult)}")
            return result
        except Exception as e:
            print(f"  - âŒ await ì‹¤íŒ¨: {type(e).__name__}: {e}")
            raise
    
    def generate(self, prompts: List[Union[str, Any]], **kwargs: Any):
        """ì¶”ì  ê¸°ëŠ¥ì´ ìˆëŠ” generate"""
        print(f"\nğŸ” generate í˜¸ì¶œë¨")
        print(f"  - ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸?: ", end="")
        try:
            loop = asyncio.get_running_loop()
            print("ì˜ˆ")
            # ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” agenerate í˜¸ì¶œ
            return self.agenerate(prompts, **kwargs)
        except RuntimeError:
            print("ì•„ë‹ˆì˜¤")
            # ë™ê¸° ì»¨í…ìŠ¤íŠ¸
            return super().generate(prompts, **kwargs)


async def test_with_ragas():
    """RAGASë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª RAGAS ë¹„ë™ê¸° í˜¸ì¶œ ì¶”ì ")
    print("=" * 70)
    
    # í™˜ê²½ ì„¤ì •
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    
    # TracingProxyë¡œ ê°ì‹¸ê¸°
    from ragtrace_lite.llm_factory import LLMAdapterWrapper, HcxAdapter
    adapter = HcxAdapter(config.llm.api_key, config.llm.model_name or "HCX-005")
    base_llm = LLMAdapterWrapper(adapter)
    llm = TracingProxy(base_llm)
    
    print(f"âœ… ì¶”ì  í”„ë¡ì‹œ ì„¤ì • ì™„ë£Œ")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_data = {
        'question': ['í•œêµ­ì˜ ìˆ˜ë„ëŠ”?'],
        'answer': ['ì„œìš¸ì…ë‹ˆë‹¤.'],
        'contexts': [['ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë‹¤.']],
        'ground_truths': [['ì„œìš¸']]
    }
    
    dataset = Dataset.from_dict(test_data)
    
    # ë©”íŠ¸ë¦­ ì„¤ì •
    faithfulness.llm = llm
    
    print("\nğŸ“Š RAGAS í‰ê°€ ì‹œì‘")
    print("-" * 50)
    
    try:
        result = await asyncio.create_task(
            asyncio.to_thread(
                evaluate,
                dataset=dataset,
                metrics=[faithfulness],
                llm=llm,
                raise_exceptions=True,
                show_progress=False
            )
        )
        print("\nâœ… í‰ê°€ ì„±ê³µ!")
    except Exception as e:
        print(f"\nâŒ í‰ê°€ ì‹¤íŒ¨: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(test_with_ragas())