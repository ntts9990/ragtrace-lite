# HCX-005 RAGAS í†µí•© ìµœì¢… êµ¬í˜„ ë³´ê³ ì„œ

## ğŸ¯ ëª©í‘œ ë‹¬ì„± í˜„í™©

### âœ… ë‹¬ì„±í•œ ëª©í‘œ
1. **HCX-005ë¥¼ ì£¼ ëª¨ë¸ë¡œ ì„¤ì •** - ì™„ë£Œ
2. **RAGAS í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰** - ì™„ë£Œ
3. **ì‹¤ì œ ì ìˆ˜ ê³„ì‚°** - ë¶€ë¶„ì  ì„±ê³µ (2/5 ë©”íŠ¸ë¦­)
4. **ë¹„ë™ê¸° ì˜¤ë¥˜ í•´ê²°** - ì™„ë£Œ

### ğŸ“Š ì‹¤ì œ í‰ê°€ ê²°ê³¼

#### ì‘ë™í•˜ëŠ” ë©”íŠ¸ë¦­ (2/5)
1. **faithfulness**: 1.000 (1/2 í•­ëª© ì„±ê³µ)
   - ì²« ë²ˆì§¸ í•­ëª©: NaN (statement ì¶”ì¶œ ì‹¤íŒ¨)
   - ë‘ ë²ˆì§¸ í•­ëª©: 1.000 âœ…

2. **answer_relevancy**: 0.353 (2/2 í•­ëª© ì„±ê³µ)
   - ì²« ë²ˆì§¸ í•­ëª©: 0.360 âœ…
   - ë‘ ë²ˆì§¸ í•­ëª©: 0.346 âœ…

#### ì‘ë™í•˜ì§€ ì•ŠëŠ” ë©”íŠ¸ë¦­ (3/5)
1. **context_precision**: ëª¨ë“  í•­ëª© NaN
   - ì˜¤ë¥˜: "Prompt context_precision_prompt failed to parse output"
   
2. **context_recall**: ëª¨ë“  í•­ëª© NaN
   - ì˜¤ë¥˜: "Prompt context_recall_classification_prompt failed to parse output"
   
3. **answer_correctness**: ëª¨ë“  í•­ëª© NaN
   - ì˜¤ë¥˜: "Prompt correctness_classifier failed to parse output"

## ğŸ”§ êµ¬í˜„ëœ í•µì‹¬ ê¸°ëŠ¥

### 1. HCX RAGAS í”„ë¡ì‹œ (`src/ragtrace_lite/hcx_proxy.py`)
- âœ… ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ìë™ ê°ì§€
- âœ… ë©”íŠ¸ë¦­ë³„ ì‘ë‹µ ë³€í™˜ ë¡œì§
- âœ… JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦
- âœ… Rate limiting ì²˜ë¦¬ (12ì´ˆ ê°„ê²©)

### 2. ë°ì´í„° ì „ì²˜ë¦¬ ê°œì„ 
- âœ… reference ì»¬ëŸ¼ ìë™ ìƒì„± (ground_truths â†’ reference)
- âœ… ì»¨í…ìŠ¤íŠ¸ í˜•ì‹ ë³€í™˜
- âœ… ë°ì´í„° ê²€ì¦ ê°•í™”

### 3. CLI í†µí•©
- âœ… `test_hcx_cli.py` - ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
- âœ… `test_full_pipeline.py` - ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
- âœ… `test_simple_eval.py` - ìƒì„¸ í‰ê°€ í…ŒìŠ¤íŠ¸

## ğŸš¨ í•´ê²°ëœ ì£¼ìš” ë¬¸ì œ

### 1. ë¹„ë™ê¸° ì˜¤ë¥˜ í•´ê²° âœ…
**ë¬¸ì œ**: `TypeError: object LLMResult can't be used in 'await' expression`

**í•´ê²°**:
```python
def generate(self, prompts, **kwargs):
    try:
        loop = asyncio.get_running_loop()
        # ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” ì½”ë£¨í‹´ ë°˜í™˜
        return self.agenerate(prompts, **kwargs)
    except RuntimeError:
        # ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” LLMResult ë°˜í™˜
        return LLMResult(generations=...)
```

### 2. Reference ì»¬ëŸ¼ ë¬¸ì œ í•´ê²° âœ…
**ë¬¸ì œ**: RAGASê°€ 'reference' ì»¬ëŸ¼ì„ ìš”êµ¬í•˜ì§€ë§Œ ë°ì´í„°ì—ëŠ” 'ground_truths'ë§Œ ìˆìŒ

**í•´ê²°**:
```python
if 'reference' not in dataset.column_names and 'ground_truths' in dataset.column_names:
    data_dict['reference'] = [gt[0] if gt else '' for gt in data_dict['ground_truths']]
    dataset = Dataset.from_dict(data_dict)
```

## ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ

- **í‰ê°€ ì‹œê°„**: ì•½ 2ë¶„ (2ê°œ í•­ëª©)
- **ì„±ê³µë¥ **: 40% (5ê°œ ë©”íŠ¸ë¦­ ì¤‘ 2ê°œ)
- **Rate limiting**: ì•ˆì •ì  (12ì´ˆ ê°„ê²© ìœ ì§€)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: ì •ìƒ ë²”ìœ„

## ğŸ” ë‚¨ì€ ë¬¸ì œ ë¶„ì„

### 1. ì¼ë¶€ ë©”íŠ¸ë¦­ì˜ JSON íŒŒì‹± ì‹¤íŒ¨
- **ì›ì¸**: HCXê°€ ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì˜ˆìƒê³¼ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
- **ì˜í–¥**: context_precision, context_recall, answer_correctness ì‚¬ìš© ë¶ˆê°€

### 2. Faithfulness ë¶€ë¶„ì  ì‹¤íŒ¨
- **ì›ì¸**: ê°„ë‹¨í•œ ë‹µë³€ì—ì„œ statement ì¶”ì¶œ ì‹¤íŒ¨
- **í•´ê²°ì±…**: ë” ê°•ë ¥í•œ statement ì¶”ì¶œ ë¡œì§ í•„ìš”

## ğŸ’¡ í–¥í›„ ê°œì„  ë°©ì•ˆ

### ë‹¨ê¸° (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥)
1. **ë©”íŠ¸ë¦­ë³„ í”„ë¡¬í”„íŠ¸ ìµœì í™”**
   ```python
   # ê° ë©”íŠ¸ë¦­ë³„ë¡œ HCXì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
   metric_prompts = {
       'context_precision': "ë‹µë³€ì´ ê´€ë ¨ìˆìœ¼ë©´ 'ì˜ˆ', ì—†ìœ¼ë©´ 'ì•„ë‹ˆì˜¤'ë¡œë§Œ ë‹µí•˜ì„¸ìš”",
       'context_recall': "ê° ë¬¸ì¥ì´ ì§€ì›ë˜ë©´ 1, ì•„ë‹ˆë©´ 0ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”"
   }
   ```

2. **í´ë°± ë©”ì»¤ë‹ˆì¦˜ ê°•í™”**
   ```python
   # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
   if parsing_failed:
       return default_scores[metric_name]
   ```

### ì¤‘ê¸° (1-2ì£¼)
1. **ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ êµ¬í˜„**
   - RAGAS ì˜ì¡´ì„± ì œê±°
   - HCX íŠ¹í™” í‰ê°€ ë¡œì§ êµ¬í˜„

2. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**
   - ê° ë©”íŠ¸ë¦­ë³„ ìµœì  í”„ë¡¬í”„íŠ¸ ì—°êµ¬
   - Few-shot ì˜ˆì œ ì¶”ê°€

### ì¥ê¸° (1ê°œì›” ì´ìƒ)
1. **HCX ì „ìš© í‰ê°€ í”„ë ˆì„ì›Œí¬**
   - RAGAS ëŒ€ì²´ ì†”ë£¨ì…˜ ê°œë°œ
   - í•œêµ­ì–´ íŠ¹í™” ë©”íŠ¸ë¦­ ì¶”ê°€

## ğŸ“ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ í‰ê°€ ì‹¤í–‰
```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export CLOVA_STUDIO_API_KEY="your-key"

# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
python test_simple_eval.py

# ì „ì²´ íŒŒì´í”„ë¼ì¸
python test_full_pipeline.py
```

### ê²°ê³¼ í™•ì¸
```bash
# CSV ê²°ê³¼ íŒŒì¼
cat test_results_detail.csv

# ì›¹ ëŒ€ì‹œë³´ë“œ
open reports/web/dashboard.html
```

## ğŸ‰ ê²°ë¡ 

HCX-005ë¥¼ RAGASì˜ ì£¼ í‰ê°€ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ **ë¶€ë¶„ì ìœ¼ë¡œ ì„±ê³µ**í–ˆìŠµë‹ˆë‹¤.

- âœ… **ë¹„ë™ê¸° ë¬¸ì œ ì™„ì „ í•´ê²°**
- âœ… **2ê°œ ë©”íŠ¸ë¦­ ì •ìƒ ì‘ë™** (faithfulness, answer_relevancy)
- âš ï¸ **3ê°œ ë©”íŠ¸ë¦­ ì¶”ê°€ ì‘ì—… í•„ìš”** (context_precision, context_recall, answer_correctness)

í˜„ì¬ ìƒíƒœì—ì„œë„ ê¸°ë³¸ì ì¸ RAG í‰ê°€ëŠ” ê°€ëŠ¥í•˜ë©°, í–¥í›„ ê°œì„ ì„ í†µí•´ ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì§€ì›í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.