#!/usr/bin/env python3
"""
ì‘ë‹µ í˜•ì‹ í™•ì¸
"""
import os
import sys
import json
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm


def test_faithfulness_response():
    """Faithfulness ì‘ë‹µ í˜•ì‹ í™•ì¸"""
    print("ğŸ” Faithfulness ì‘ë‹µ í˜•ì‹ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    llm = create_llm(config)
    
    # RAGASê°€ ì‚¬ìš©í•˜ëŠ” ì‹¤ì œ í”„ë¡¬í”„íŠ¸
    prompt = """Given the following question, answer, and context, 
extract factual statements from the answer.

Question: í•œêµ­ì˜ ìˆ˜ë„ëŠ”?
Answer: ì„œìš¸ì…ë‹ˆë‹¤.
Context: ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë‹¤.

Extract statements from the answer that can be verified."""
    
    print("ğŸ“ í”„ë¡¬í”„íŠ¸:")
    print(prompt)
    print("\n" + "-" * 50)
    
    # 1. í”„ë¡ì‹œ ì‘ë‹µ
    print("\n1ï¸âƒ£ í”„ë¡ì‹œ ì‘ë‹µ:")
    response = llm._call(prompt)
    print(f"íƒ€ì…: {type(response)}")
    print(f"ë‚´ìš©: {response}")
    
    # JSON íŒŒì‹± ì‹œë„
    try:
        data = json.loads(response)
        print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {list(data.keys())}")
        print(f"ê°’ íƒ€ì…ë“¤: {[(k, type(v)) for k, v in data.items()]}")
    except Exception as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    
    # 2. ë² ì´ìŠ¤ LLM ì§ì ‘ í˜¸ì¶œ
    print("\n2ï¸âƒ£ ë² ì´ìŠ¤ LLM ì§ì ‘ í˜¸ì¶œ:")
    if hasattr(llm, 'hcx'):
        base_response = llm.hcx._call(prompt)
        print(f"íƒ€ì…: {type(base_response)}")
        print(f"ë‚´ìš©: {base_response}")
        
        try:
            base_data = json.loads(base_response)
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {list(base_data.keys())}")
        except:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
    
    # 3. ì–´ëŒ‘í„° ì§ì ‘ í˜¸ì¶œ
    print("\n3ï¸âƒ£ ì–´ëŒ‘í„° ì§ì ‘ í˜¸ì¶œ:")
    if hasattr(llm, 'hcx') and hasattr(llm.hcx, 'adapter'):
        adapter_response = llm.hcx.adapter.generate_answer(prompt)
        print(f"íƒ€ì…: {type(adapter_response)}")
        print(f"ë‚´ìš©: {adapter_response}")


def test_answer_relevancy_response():
    """Answer Relevancy ì‘ë‹µ í˜•ì‹ í™•ì¸"""
    print("\n\nğŸ” Answer Relevancy ì‘ë‹µ í˜•ì‹ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    os.environ['CLOVA_STUDIO_API_KEY'] = "nv-d78e840d8f5c4e2faed883a52ea91375gmj8"
    config = load_config()
    llm = create_llm(config)
    
    # RAGASê°€ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í˜•ì‹
    prompt = """Generate a question for the given answer.

Answer: ì„œìš¸ì…ë‹ˆë‹¤.
Context: ì„œìš¸ì€ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ë‹¤.

Generate a question to which the given answer would be appropriate."""
    
    print("ğŸ“ í”„ë¡¬í”„íŠ¸:")
    print(prompt)
    print("\n" + "-" * 50)
    
    # í”„ë¡ì‹œ ì‘ë‹µ
    print("\ní”„ë¡ì‹œ ì‘ë‹µ:")
    response = llm._call(prompt)
    print(f"ë‚´ìš©: {response}")
    
    try:
        data = json.loads(response)
        print(f"âœ… JSON êµ¬ì¡°: {json.dumps(data, indent=2, ensure_ascii=False)}")
    except Exception as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    test_faithfulness_response()
    test_answer_relevancy_response()