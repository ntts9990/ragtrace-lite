#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ RAGAS í‰ê°€ í…ŒìŠ¤íŠ¸
"""
import os
import sys
import pandas as pd
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ragtrace_lite.config_loader import load_config
from ragtrace_lite.llm_factory import create_llm
from ragtrace_lite.evaluator import RagasEvaluator
from datasets import Dataset


def test_simple_evaluation():
    """ê°„ë‹¨í•œ í‰ê°€ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ§ª ê°„ë‹¨í•œ RAGAS í‰ê°€ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # ì„¤ì • ë¡œë“œ
    config = load_config()
    llm = create_llm(config)
    print(f"âœ… LLM ë¡œë“œ: {type(llm).__name__}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë” ë³µì¡í•œ ì˜ˆì œ)
    test_data = {
        'question': [
            'í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?',
            'Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?'
        ],
        'answer': [
            'í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì€ ì•½ 950ë§Œ ëª…ì˜ ì¸êµ¬ê°€ ê±°ì£¼í•˜ëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ì˜ ë„ì‹œì…ë‹ˆë‹¤. ì„œìš¸ì€ ì¡°ì„ ì‹œëŒ€ë¶€í„° í˜„ì¬ê¹Œì§€ 600ë…„ ì´ìƒ í•œêµ­ì˜ ìˆ˜ë„ ì—­í• ì„ í•´ì™”ìŠµë‹ˆë‹¤.',
            'ë¦¬ìŠ¤íŠ¸ëŠ” ê°€ë³€(mutable) ê°ì²´ë¡œ ìš”ì†Œë¥¼ ì¶”ê°€, ì‚­ì œ, ìˆ˜ì •í•  ìˆ˜ ìˆì§€ë§Œ, íŠœí”Œì€ ë¶ˆë³€(immutable) ê°ì²´ë¡œ í•œ ë²ˆ ìƒì„±ë˜ë©´ ë³€ê²½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¦¬ìŠ¤íŠ¸ëŠ” ëŒ€ê´„í˜¸ []ë¥¼ ì‚¬ìš©í•˜ê³ , íŠœí”Œì€ ì†Œê´„í˜¸ ()ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.'
        ],
        'contexts': [
            [
                'ì„œìš¸íŠ¹ë³„ì‹œëŠ” ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ì´ì ìµœëŒ€ ë„ì‹œë¡œ, ì •ì¹˜, ê²½ì œ, ë¬¸í™”ì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤.',
                'ì„œìš¸ì˜ ì¸êµ¬ëŠ” ì•½ 950ë§Œ ëª…ìœ¼ë¡œ ì „ì²´ ì¸êµ¬ì˜ ì•½ 18%ê°€ ê±°ì£¼í•©ë‹ˆë‹¤.',
                'ì„œìš¸ì€ 1394ë…„ ì¡°ì„ ì˜ ìˆ˜ë„ë¡œ ì •í•´ì§„ ì´í›„ í˜„ì¬ê¹Œì§€ í•œêµ­ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤.'
            ],
            [
                'Pythonì˜ ë¦¬ìŠ¤íŠ¸ëŠ” ëŒ€ê´„í˜¸ []ë¥¼ ì‚¬ìš©í•˜ë©°, ë™ì ìœ¼ë¡œ í¬ê¸°ê°€ ë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
                'íŠœí”Œì€ ì†Œê´„í˜¸ ()ë¥¼ ì‚¬ìš©í•˜ë©°, ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  í•´ì‹œ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                'ë¦¬ìŠ¤íŠ¸ëŠ” append(), remove() ë“±ì˜ ë©”ì„œë“œë¡œ ìˆ˜ì • ê°€ëŠ¥í•˜ì§€ë§Œ, íŠœí”Œì€ ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            ]
        ],
        'ground_truths': [
            ['í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤.'],
            ['ë¦¬ìŠ¤íŠ¸ëŠ” ë³€ê²½ ê°€ëŠ¥í•˜ê³  íŠœí”Œì€ ë³€ê²½ ë¶ˆê°€ëŠ¥í•˜ë‹¤.']
        ]
    }
    
    dataset = Dataset.from_dict(test_data)
    print(f"âœ… ë°ì´í„°ì…‹ ìƒì„±: {len(dataset)}ê°œ í•­ëª©\n")
    
    # í‰ê°€ì ìƒì„± ë° í‰ê°€ ì‹¤í–‰
    evaluator = RagasEvaluator(config, llm=llm)
    
    print("ğŸ“Š RAGAS í‰ê°€ ì‹¤í–‰...")
    results_df = evaluator.evaluate(dataset)
    
    print("\n" + "="*60)
    print("ğŸ“ˆ í‰ê°€ ê²°ê³¼")
    print("="*60)
    
    # ê²°ê³¼ í™•ì¸
    if isinstance(results_df, pd.DataFrame):
        print(f"âœ… ê²°ê³¼ DataFrame í¬ê¸°: {results_df.shape}")
        print(f"âœ… ì»¬ëŸ¼: {list(results_df.columns)}")
        
        # ì ìˆ˜ ì¶œë ¥
        metric_cols = [col for col in results_df.columns 
                      if col not in ['user_input', 'retrieved_contexts', 'response', 'reference', 
                                     'question', 'answer', 'contexts', 'ground_truths']]
        
        print("\nğŸ“Š ë©”íŠ¸ë¦­ë³„ ì ìˆ˜:")
        for metric in metric_cols:
            if metric in results_df.columns:
                scores = pd.to_numeric(results_df[metric], errors='coerce')
                valid_scores = scores.dropna()
                if len(valid_scores) > 0:
                    print(f"  - {metric}: {valid_scores.mean():.3f} (Â±{valid_scores.std():.3f})")
                    for i, score in enumerate(scores):
                        if pd.notna(score):
                            print(f"    â€¢ í•­ëª© {i+1}: {score:.3f}")
                        else:
                            print(f"    â€¢ í•­ëª© {i+1}: NaN")
                else:
                    print(f"  - {metric}: ëª¨ë“  ì ìˆ˜ê°€ NaN")
        
        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        output_path = "test_results_detail.csv"
        results_df.to_csv(output_path, index=False)
        print(f"\nâœ… ìƒì„¸ ê²°ê³¼ ì €ì¥: {output_path}")
        
    else:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ íƒ€ì…: {type(results_df)}")
    
    print("\n" + "="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*80)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_simple_evaluation()